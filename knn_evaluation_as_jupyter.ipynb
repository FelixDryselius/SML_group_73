{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All the imports and data import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.preprocessing as skl_pre\n",
    "import sklearn.linear_model as skl_lm\n",
    "import sklearn.discriminant_analysis as skl_da\n",
    "import sklearn.neighbors as skl_nb\n",
    "import sklearn.model_selection as skl_ms\n",
    "import sklearn.metrics as met\n",
    "from tabulate import tabulate\n",
    "\n",
    "import os, sys\n",
    "\n",
    "cwd = os.getcwd()\n",
    "#URI = (cwd+\"\\\\train.csv\")\n",
    "URI = (cwd+\"\\\\train_standardscaler.csv\")\n",
    "#URI = (cwd+\"\\\\train_minmaxscaler.csv\")\n",
    "film_data = pd.read_csv(URI, dtype={\"Lead\":str}).dropna().reset_index(drop=True)\n",
    "\n",
    "x = film_data.drop(columns=['Lead'])\n",
    "y = film_data['Lead']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "#Choosing 85% random row numbers\n",
    "train_size = (film_data.shape[0]*85)//100\n",
    "train_rows = np.random.choice(film_data.shape[0], size=train_size, replace=False)\n",
    "\n",
    "#Creating a bool array where True means that that row is in training data\n",
    "train_index = film_data.index.isin(train_rows)\n",
    "train_set = film_data.iloc[train_index]\n",
    "test_set = film_data.iloc[~train_index]\n",
    "\n",
    "x_train = x.iloc[train_index]\n",
    "y_train = y.iloc[train_index]\n",
    "x_test = x.iloc[~train_index]\n",
    "y_test = y.iloc[~train_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I do feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I do Kfold cross validation\n",
    "n_folds = 250\n",
    "\n",
    "Kfold_cv= skl_ms.KFold(shuffle=True,n_splits=n_folds)\n",
    "\n",
    "#Testing k in range *\n",
    "k_range = np.arange(1,80)\n",
    "\n",
    "missclassification_error = np.zeros(len(k_range))\n",
    "\n",
    "\n",
    "\n",
    "for train_index, val_index in Kfold_cv.split(x):\n",
    "\tx_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "\ty_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\t\n",
    "\tfor index, k in enumerate(k_range):\n",
    "\t\tmodel = skl_nb.KNeighborsClassifier(n_neighbors=k)\n",
    "\t\tmodel.fit(x_train, y_train)\n",
    "\t\tprediction = model.predict(x_val)\n",
    "\t\tmissclassification_error[index] += np.mean(prediction != y_val)\n",
    "\n",
    "missclassification_error /= n_folds\n",
    "plt.plot(k_range, missclassification_error)\n",
    "plt.title(f\"Cross validation KFold = {n_folds} error for kNN\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Validation error\")\n",
    "plt.show() \n",
    "\n",
    "min_error = np.min(missclassification_error)\n",
    "min_error_k = [i for i, x in enumerate(missclassification_error) if x == min_error] [0]+1\n",
    "\n",
    "\n",
    "print_table = [[\"Term\",\"Value\"],\n",
    "                [\"'Postive class'\", \"Male\"],\n",
    "                [\"Optimal k\", min_error_k],\n",
    "                [\"E[error_new]\", min_error]]\n",
    "\n",
    "print(tabulate(print_table, headers=(\"firstrow\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wan't to choose my hyper variables, which is \"k\" in this setting. \n",
    "\n",
    "I will choose \"k\" with the use of the \"leave one out\" method of cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loo = skl_ms.LeaveOneOut()\n",
    "#print(loo)\n",
    "\n",
    "#Testing k in range 1-20\n",
    "k_range = np.arange(1,30)\n",
    "\n",
    "missclassification_error = np.zeros(len(k_range))\n",
    "\n",
    "n_folds = loo.get_n_splits(x)\n",
    "\n",
    "for train_index, val_index in loo.split(x):\n",
    "\tx_train, x_val = x.iloc[train_index], x.iloc[val_index]\n",
    "\ty_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\t\n",
    "\tfor index, k in enumerate(k_range):\n",
    "\t\tmodel = skl_nb.KNeighborsClassifier(n_neighbors=k)\n",
    "\t\tmodel.fit(x_train, y_train)\n",
    "\t\tprediction = model.predict(x_val)\n",
    "\t\tmissclassification_error[index] += np.mean(prediction != y_val)\n",
    "\n",
    "missclassification_error /= n_folds\n",
    "plt.plot(k_range, missclassification_error)\n",
    "plt.title(\"Cross validation LeaveOneOut error for kNN\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Validation error\")\n",
    "plt.show() \n",
    "\n",
    "min_error = np.min(missclassification_error)\n",
    "min_error_k = [i for i, x in enumerate(missclassification_error) if x == min_error] [0]+1\n",
    "\n",
    "print_table = [[\"Term\",\"Value\"],\n",
    "                [\"'Postive class'\", \"Male\"],\n",
    "                [\"Optimal k\", min_error_k],\n",
    "                [\"E[error_new]\", min_error]]\n",
    "\n",
    "print(tabulate(print_table, headers=(\"firstrow\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing important valuables\n",
    "\n",
    "Heatmap as crosstab validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Here I do crosstab valuation, ROC curve, etc\n",
    "K= 18\n",
    "\n",
    "model = skl_nb.KNeighborsClassifier(n_neighbors=K)\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "\n",
    "predict_prob = model.predict_proba(x_test)[::,1]\n",
    "\n",
    "\n",
    "\n",
    "#Evaluation terms:\n",
    "positive_class = \"Male\"\n",
    "negative_class = \"Female\"\n",
    "\n",
    "P = np.sum(y_test == positive_class)\n",
    "N = np.sum(y_test == negative_class)\n",
    "\n",
    "TN, FP, FN, TP = met.confusion_matrix(y_test,prediction).ravel()\n",
    "\n",
    "cm=np.array([[TN,FP],[FN,TP]])\n",
    "#cm= met.confusion_matrix(y_test,prediction, labels=[positive_class, negative_class])\n",
    "\n",
    "disp = met.ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[positive_class, negative_class])\n",
    "\n",
    "predict_prob = model.predict_proba(x_test)[::,1]\n",
    "FPR, TPR, threshold = met.roc_curve(y_test,  predict_prob, pos_label=\"Male\" )\n",
    "\n",
    "disp.plot()\n",
    "\n",
    "pd.crosstab(y_test, prediction, margins=True)\n",
    "\n",
    "\n",
    "Table_eval_terms = [[\"Evaluation Term\",\"Value\"],\n",
    "                    [\"Optimal k\", 12],   #min_error_k\n",
    "                    [\"'Postive class'\", \"Male\"],\n",
    "                    [\"Total Positive class\", P],\n",
    "                    [\"Total Negative class\", N],\n",
    "                    [\"True Positive\", TN],\n",
    "                    [\"False Positive\", FP],\n",
    "                    [\"False Negative\", FN],\n",
    "                    [\"True Positive\", TP]]\n",
    "\n",
    "\n",
    "print(tabulate(Table_eval_terms, headers=(\"firstrow\")))\n",
    "\n",
    "\n",
    "print(type(cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two ways of doing a ROC-curve, first is built in functions the other is manual. \n",
    "\n",
    "Because value of 'r' doesn't matter to kNN, plotting of The precision-recall curve is not performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K =12\n",
    "\n",
    "\n",
    "#ROC CURVE, AUTOMATIC\n",
    "model = skl_nb.KNeighborsClassifier(n_neighbors=K)\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "\n",
    "predict_prob = model.predict_proba(x_test)[::,1]\n",
    "FPR, TPR, threshold = met.roc_curve(y_test,  predict_prob, pos_label=\"Male\" )\n",
    "#FPR, TPR, threshold = met.precision_recall_curve(y_test,  predict_prob, pos_label=\"Male\" )\n",
    "\n",
    "print(type(FPR))\n",
    "\n",
    "#create ROC curve\n",
    "plt.plot(FPR,TPR)\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#ROC CURVE MANUALLY\n",
    "\n",
    "true_positive_rate = []\n",
    "false_positive_rate = []\n",
    "\n",
    "positive_class = \"Male\"\n",
    "negative_class = \"Female\"\n",
    "\n",
    "P = np.sum(y_test == positive_class)\n",
    "N = np.sum(y_test == negative_class)\n",
    "\n",
    "threshold = np.linspace(0,1,201)\n",
    "model = skl_nb.KNeighborsClassifier(n_neighbors=12)\n",
    "model.fit(x_train, y_train)\n",
    "prediction = model.predict(x_test)\n",
    "\n",
    "predict_prob = model.predict_proba(x_test)\n",
    "\n",
    "positive_class_index = np.argwhere(model.classes_== positive_class).squeeze()\n",
    "\n",
    "for r in threshold:\n",
    "    prediction = np.where(predict_prob[:, positive_class_index]> r, positive_class, negative_class)\n",
    "    FP = np.sum((prediction == positive_class) & (y_test == negative_class))\n",
    "    TP = np.sum((prediction == positive_class) & (y_test == positive_class))\n",
    "    false_positive_rate.append(FP/N)\n",
    "    true_positive_rate.append(TP/P)\n",
    "print(true_positive_rate)\n",
    "plt.plot(false_positive_rate, true_positive_rate);\n",
    "\n",
    "threshold_steps = threshold.size -1\n",
    "check_r_at_percentage = [0,1,10,50,80,100]\n",
    "index_list = list(np.array(check_r_at_percentage)*threshold_steps//100)\n",
    "print(index_list)\n",
    "\n",
    "for idx in index_list:\n",
    "    print(idx)\n",
    "    plt.text(false_positive_rate[idx], true_positive_rate[idx], f\"r={threshold[idx]:.2f}\")\n",
    "\n",
    "plt.xlim([0,1.05])\n",
    "plt.ylim([0,1.1])\n",
    "plt.xlabel(\"False positive rate\")\n",
    "plt.ylabel(\"True positive rate\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3111baa9af51e81b1c55f9e9a85a0777aa6adeb733b62bd6ba4d28d54b1a7202"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
